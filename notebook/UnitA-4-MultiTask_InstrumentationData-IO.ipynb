{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiTask and Instrumentation Data I/O\n",
    "\n",
    "J. M. Hughes. Real World Instrumentation with Python, O'Reilly Media, December 2010, ISBN 978-0-596-80956-0\n",
    "\n",
    "* CHAPTER 11 Instrumentation Data I/O\n",
    "\n",
    "  * Data I/O: Acquiring and Writing Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Blocking Versus Nonblocking Calls \n",
    "\n",
    "Now it’s time to introduce some concepts that you will need to use later to build robust and reliable software. We’ll start with a discussion of blocking and nonblocking function calls, and then take a look at some basic techniques for handling errors.\n",
    "\n",
    "One way to describe the behavior of a function or method is `in terms of how quickly it will return after it has been invoked`. Some only return `after` a result of some type is obtained, while others may return `immediately` without waiting for something else downstream to produce a particular response.\n",
    "\n",
    "In other words, functions is\n",
    "\n",
    "* **blocking** : the calling code must **wait** for a response \n",
    "\n",
    "* **nonblocking** : the call returns **immediately**, usually with a response that indicates success or failure\n",
    "\n",
    "Actually, all software functions (and methods, too) can be classified as either `blocking or nonblocking`, and the majority of functions within a typical software application are of the blocking variety—that is, they don’t return until the intended action is complete or an error is detected. \n",
    "\n",
    "### 1.1 Blocking \n",
    "\n",
    "You can see this in the **message sequence chart (MSC)(消息序列图)** shown in `Figure 11-9`.\n",
    "\n",
    "Here we have `Function1()` calling `Function2()`, which in turn calls `Function3()` and finally `Function4()`. The time required for `Function1()` to receive a response from `Function2()` is dependent on how long it takes for functions 2, 3, and 4 to complete their processing and return. During this entire time, **Function1()** is blocked.(In an MSC diagram, events in a function or process occur in a top-to-bottom order,and transactions between functions or processes are the horizontal lines.)\n",
    "\n",
    "![data-io-msc](./img/data-io-msc.jpg)\n",
    "\n",
    ">**Message sequence charts**\n",
    "The message sequence chart (MSC) is defined by the guidelines document Z.120, maintained by the `International Telecommunication Union (ITU)`. In its current form, an MSC is a powerful tool for modeling command-response transactions between multiple entities. The UML equivalent of the MSC is the **sequence diagram**\n",
    "\n",
    "**Blocking** allows functions to maintain **synchronization(同步) and honor the intended flow of execution** through the code. The action or data that the call is requesting may or may **not be available** at the time the call is made, so a `blocking` call will `wait` for the other end to respond in some fashion before returning to the caller. As a side effect, it will also effectively `suspend your application` until it returns.\n",
    "\n",
    "**The type of blocking** we’re most interested in is when an application process is forced to **wait for an interface**, which in turn waits for a `hardware device to respond`. \n",
    "\n",
    "#### 1.1.1 Blocking IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin of the call at the second: 34\n",
      "cpu_percent: 13.4\n",
      "End of the call at  the second: 36\n",
      "Begin of the call at the second: 36\n",
      "cpu_percent: 11.1\n",
      "End of the call at  the second: 38\n",
      "Begin of the call at the second: 38\n",
      "cpu_percent: 5.3\n",
      "End of the call at  the second: 40\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "\n",
    "def get_data():\n",
    "    time.sleep(2)\n",
    "    return psutil.cpu_percent()\n",
    "\n",
    "def cpu_monitor_sync():\n",
    "    \"\"\" blocking I/O call\"\"\"\n",
    "    return get_data()\n",
    "  \n",
    "for i in  range(3):\n",
    "   # blocking call\n",
    "    time1=time.localtime(time.time())\n",
    "    print(\"Begin of the call at the second:\",str(time1.tm_sec))\n",
    "    values=cpu_monitor_sync()\n",
    "    print(\"cpu_percent:\",values)\n",
    "    time2=time.localtime(time.time())\n",
    "    print(\"End of the call at  the second:\",str(time2.tm_sec))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 The Simplest Monitor using Matplotlib.Plot\n",
    "\n",
    "```python\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "Set `interval=1000`\n",
    "```python\n",
    "ani = FuncAnimation(fig, update,init_func=init, blit=True,interval=1000)\n",
    "```\n",
    "Test\n",
    "\n",
    "1. The times of Blocking IO > the `interval=1000`\n",
    "\n",
    "```python\n",
    "time.sleep(2)\n",
    "```\n",
    "\n",
    "2. The times of Blocking IO < the `interval=1000`\n",
    "\n",
    "```python\n",
    "time.sleep(0.1)\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/concurrency/demo_blocking_io_cpu_simplest_monitor_matplotlib.py\n"
     ]
    }
   ],
   "source": [
    "%%file ./code/concurrency/demo_blocking_io_cpu_simplest_monitor_matplotlib.py\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import psutil\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "def virtual_interface_data(tag):\n",
    "    # time.sleep(0.1)\n",
    "    try:\n",
    "        if tag==\"CPU_PERCENT\":\n",
    "            value=psutil.cpu_percent()\n",
    "        elif tag==\"MEM_PERCENTT\":\n",
    "            value=psutil.virtual_memory().percent\n",
    "        rc=1    \n",
    "    except:\n",
    "        rc,value=0,None  \n",
    "    return (rc,value)        \n",
    "            \n",
    "tag=\"CPU_PERCENT\"\n",
    "y = deque()\n",
    "\n",
    "columns = ()\n",
    "col_labels = ['Tag', 'Unit', 'Value']\n",
    "table_vals = [[tag,\"%\",\"\"]]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"The Simplest Monitor:\"+tag)\n",
    "ln, = plt.plot([], [], 'b-o')\n",
    "str_cursecond=str(time.localtime(time.time()).tm_sec)   \n",
    "time_text = ax.text(0.5, 80, \"\")\n",
    "\n",
    "tbl = ax.table(cellText=table_vals,\n",
    "               colLabels=col_labels,\n",
    "               colWidths=[0.2] * 3,\n",
    "               cellLoc='center',\n",
    "               loc='best')\n",
    "\n",
    "def init():\n",
    "    ax.set_xlim(0, 9)\n",
    "    ax.set_ylim(0, 100)\n",
    "    return ln,\n",
    "\n",
    "def update(frames):\n",
    "    rc,value = virtual_interface_data(tag)\n",
    "    if len(y) < 10:\n",
    "        y.append(value)\n",
    "    else:\n",
    "        y.popleft()\n",
    "        y.append(value)\n",
    "\n",
    "    str_curtime=time.strftime(\"%F %H:%M:%S\", time.localtime(time.time()))\n",
    "    time_text.set_text(\"Time:\"+str_curtime)\n",
    "    \n",
    "    table_vals = [[tag,\"%\",str(value)]]\n",
    "    tbl = ax.table(cellText=table_vals,\n",
    "               colLabels=col_labels,\n",
    "               colWidths=[0.2] *3,\n",
    "               cellLoc='center',\n",
    "               loc='best')\n",
    "\n",
    "    ln.set_xdata(np.arange(len(y)))\n",
    "    ln.set_ydata(np.array(y))\n",
    "    return ln,time_text, tbl\n",
    "\n",
    "ani = FuncAnimation(fig, update,init_func=init, blit=True,interval=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases it `may not matter` if a blocking call `waits for a bit` before returning to the caller, and allowing this is more convenient than writing the necessary code to support continual query and retry actions.\n",
    "\n",
    "But, there is a warning in order here: when working with I/O devices, **a blocking call without a timeout of some sort** can potentially **hang forever**. This is usually a bad thing, and often the only way to get out of the situation is to shut down Python and restart the application. If your code is running on an unattended machine somewhere in the middle of nowhere, a fault that hangs a blocking call can be really, really bad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Threads\n",
    "\n",
    "The programs often need to perform several tasks simultaneously. For example, a program may:\n",
    "\n",
    "* Execute procedures that accomplish intermediate tasks in **parallel** and so improve performance\n",
    "\n",
    "* Process user **input** while carrying on time-consuming data communication or real-time operations `“in the background”`\n",
    "\n",
    "Different tasks are performed simultaneously by the **concurrent execution** of parts of the program. Especially on modern multiprocessor systems — including multicore processors,of course — it is increasingly important for programs to take advantage of concurrency to use the system’s resources efficiently.\n",
    "\n",
    "When you start a program, the operating system creates a new **process(进程)** in which the program is executed. A process consists of one or more **threads(线程)**. Each thread is a partial process that executes a sequence of instructions **independently** of other parts of the process.\n",
    "\n",
    "When the process begins, its **main thread** is active. From then on, any running thread can launch other threads.\n",
    "\n",
    "All threads that have been started but not yet ended are `terminated when the process terminates`.\n",
    "\n",
    "Every process has its own address space in memory, and has other exclusive resources, such as open files. All the threads of a process inherit its resources. Most significantly,several **threads** in one process `share` the **same address space.**\n",
    "\n",
    "Because the threads of a given process use the **same address space**, they share their global and static data. That means, however, that two different threads can access the same memory locations concurrently. This situation is called a **race condition(竞争条件)**. To prevent **inconsistencies** in shared data, the programmer must **explicitly `synchronize` different threads**’ writing operations or reading and writing operations if they use the same locations in memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 threading Module\n",
    "\n",
    "The threading module provides APIs for managing several threads of execution, which allows a program to run multiple operations concurrently in the same process space.\n",
    "\n",
    "The simplest way to use a **Thread** is to instantiate it with a **target** function and call **start()** to let it begin working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Worker 0 at 2019-05-01 01:52:04.899010\n",
      "Worker 2 at 2019-05-01 01:52:04.906013\n",
      "Worker 3 at 2019-05-01 01:52:04.915010\n",
      "Worker 4 at 2019-05-01 01:52:04.922025\n",
      "Worker 1 at 2019-05-01 01:52:04.931988"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def worker(num):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    time.sleep(2.0)\n",
    "    str_curtime=datetime.datetime.now().strftime('%F %H:%M:%S.%f')\n",
    "    print('\\nWorker {} at {}'.format(num,str_curtime),end=\"\")\n",
    "\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker,args=(i,))\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Daemon thread\n",
    "\n",
    "Up to this point, the example programs have **implicitly** waited to exit until all threads have completed their work.\n",
    "\n",
    "Sometimes, however, programs spawn a thread as a **daemon(守护/后台）** that runs without blocking the main program from exiting. \n",
    "\n",
    "**Daemon threads** are useful for services where there may not be an easy way to interrupt the thread, or where letting the thread\n",
    "die in the middle of its work does not lead to loss or corruption of data(主线程退出时,不需要等待daemon子线程完成）\n",
    "\n",
    "To mark a thread as a daemon, pass `daemon=True` when constructing it or call its `setDaemon()` method with `True`. The default is for threads to not be daemons.\n",
    "\n",
    ">The **logging** module supports `embedding the thread name` in every log message using the formatter code %(threadName)s.Including thread names in log messages makes it possible to trace those messages back to their source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/concurrency/threading_daemon.py\n"
     ]
    }
   ],
   "source": [
    "%%file ./code/concurrency/threading_daemon.py\n",
    "import threading\n",
    "import time\n",
    "import logging\n",
    "\n",
    "def daemon():\n",
    "    logging.debug('Starting')\n",
    "    time.sleep(2)\n",
    "    logging.debug('Exiting')\n",
    "\n",
    "def non_daemon():\n",
    "    logging.debug('Starting')\n",
    "    logging.debug('Exiting')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='(%(threadName)-10s) %(message)s',\n",
    ")\n",
    "\n",
    "d = threading.Thread(name='daemon', target=daemon, daemon=True)\n",
    "t = threading.Thread(name='non-daemon', target=non_daemon)\n",
    "d.start()\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(daemon    ) Starting\n",
      "(non-daemon) Starting\n",
      "(non-daemon) Exiting\n"
     ]
    }
   ],
   "source": [
    "!python ./code/concurrency/threading_daemon.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from this code does not include the **\"Exiting\"** message from the **daemon** thread\n",
    "\n",
    "since all of the non-daemon threads (including the main thread) exit before the daemon thread wakes up from the `time.sleep()` call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 join() Method\n",
    "\n",
    "```python\n",
    "join(timeout=None)\n",
    "```\n",
    "Wait until the thread terminates. This blocks the calling thread until the thread whose `join()` method is called terminates\n",
    "\n",
    "* either normally or through an unhandled exception \n",
    "\n",
    "* until the optional timeout occurs.\n",
    "\n",
    "Use the **join()** method to wait until a `daemon` thread has completed its work, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/concurrency/threading_daemon_join.py\n"
     ]
    }
   ],
   "source": [
    "%%file ./code/concurrency/threading_daemon_join.py\n",
    "import threading\n",
    "import time\n",
    "import logging\n",
    "\n",
    "def daemon():\n",
    "    logging.debug('Starting')\n",
    "    time.sleep(3)\n",
    "    logging.debug('Exiting')\n",
    "\n",
    "def non_daemon():\n",
    "    logging.debug('Starting')\n",
    "    logging.debug('Exiting')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='(%(threadName)-10s) %(message)s',\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "d = threading.Thread(name='daemon', target=daemon, daemon=True)\n",
    "t = threading.Thread(name='non-daemon', target=non_daemon)\n",
    "d.start()\n",
    "t.start()\n",
    "d.join()\n",
    "t.join()\n",
    "print(threading.current_thread().name+\" Exiting!\")\n",
    "print('Total Time：', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread Exiting!\n",
      "Total Time： 3.0022974014282227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(daemon    ) Starting\n",
      "(non-daemon) Starting\n",
      "(non-daemon) Exiting\n",
      "(daemon    ) Exiting\n"
     ]
    }
   ],
   "source": [
    "!python ./code/concurrency/threading_daemon_join.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Subclassing Thread\n",
    "\n",
    "At start-up, a Thread does some basic initialization and then calls its **run()** method, which in turn calls the `target` function passed to the constructor.\n",
    "\n",
    "To create a subclass of Thread, override `run()` to do whatever is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/concurrency/threading_subclass.py\n"
     ]
    }
   ],
   "source": [
    "%%file ./code/concurrency/threading_subclass.py\n",
    "import threading\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "class MyThread(threading.Thread):\n",
    "    \n",
    "    def run(self):\n",
    "        time.sleep(2.0)\n",
    "        str_curtime=datetime.datetime.now().strftime('%F %H:%M:%S.%f')\n",
    "        logging.debug('running at '+ str_curtime)\n",
    "        \n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='(%(threadName)-10s) %(message)s',)\n",
    "\n",
    "def main():\n",
    "    for i in range(5):\n",
    "        t = MyThread()\n",
    "        t.start() \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Thread-1  ) running at 2019-05-01 01:52:50.656306\n",
      "(Thread-2  ) running at 2019-05-01 01:52:50.656306\n",
      "(Thread-5  ) running at 2019-05-01 01:52:50.657240\n",
      "(Thread-3  ) running at 2019-05-01 01:52:50.657240\n",
      "(Thread-4  ) running at 2019-05-01 01:52:50.657240\n"
     ]
    }
   ],
   "source": [
    "!python ./code/concurrency/threading_subclass.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thread’s **start** method `automatically` invokes its **run** method. \n",
    "\n",
    "The **Thread** class maintains an instance variable for the thread’s name and includes the associated methods `getName` and `setName`. \n",
    "\n",
    "The Table lists **some important Thread methods.**\n",
    "\n",
    "|Thread Method| What It Does|\n",
    "|:---------:|:--------:|\n",
    "|__init__(name = None)| Initializes the thread’s name.|\n",
    "|getName()| Returns the thread’s name.|\n",
    "|setName(newName)| Sets the thread’s name to newName.|\n",
    "|run() |Executes when the thread acquires the CPU.|\n",
    "|start()| Makes the new thread ready. Raises an exception if run more than once. |\n",
    "| isAlive()| Returns True if the thread is alive or False otherwise |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Non-blocking\n",
    "\n",
    "One way to deal with this is to use **nonblocking** function calls. This entails some `additional` code, but it’s very useful when dealing with network communications and data acquisition. \n",
    "\n",
    "**Threading** is a technique for decoupling tasks which are not sequentially dependent. Threads can be used to improve the responsiveness of applications that accept user input while other tasks run in the background. \n",
    "\n",
    "* A related use case is running I/O in parallel with computations in another thread.\n",
    "\n",
    "This is shown in Figure 11-10. Notice that there is a **timer** symbol in this diagram. This means that if the hardware does not respond within some preset period of time, `the interface process will terminate and return an error`\n",
    "\n",
    "![data-io-io](./img/data-io-io.jpg)\n",
    "\n",
    "We’ll look at some ways to realize **nonblocking** function using **Concurrency Programming**.\n",
    "\n",
    "To implement concurrency, it is necessary to think and code differently; in the following sections, we'll demonstrate techniques and best practices to implement **robust concurrent applications**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Non-blocking with timeout using threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ./code/concurrency/nonblocking_io_cpu.py\n",
    "\"\"\"\n",
    "  https://blog.csdn.net/MeteorCountry/article/details/82765919\n",
    "\"\"\"\n",
    "import psutil\n",
    "import time\n",
    "import threading\n",
    "\n",
    "class IOThread(threading.Thread): \n",
    "    \n",
    "    def __init__(self,target,args=()):  \n",
    "        super(IOThread,self).__init__()\n",
    "        self.func = target\n",
    "        self.args = args\n",
    "        \n",
    "    def run(self):\n",
    "        self.result = self.func(*self.args) \n",
    "            \n",
    "    def get_result(self):\n",
    "        try:   \n",
    "            return self.result\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "def timeout_decor(timeout): \n",
    "    \"\"\" timeout: max time,s  \n",
    "        return: if timeout ,return None \n",
    "    \"\"\" \n",
    "    def functions(func): \n",
    "    \n",
    "        def run(*params):\n",
    "            thre_func = IOThread(target=func,args=params)\n",
    "            # if timeout,main thread stop,then the iothread is stoped \n",
    "            thre_func.setDaemon(True)\n",
    "            thre_func.start()\n",
    "            sleep_num = int(timeout // 1)\n",
    "            sleep_nums = round(timeout % 1, 1) \n",
    "            for i in range(sleep_num):\n",
    "                time.sleep(1)\n",
    "                infor = thre_func.get_result()\n",
    "                if infor:\n",
    "                    return infor\n",
    "            time.sleep(sleep_nums)\n",
    "            return thre_func.get_result()       \n",
    "            \n",
    "        return run\n",
    "    \n",
    "    \n",
    "    return functions\n",
    "\n",
    "def get_data_with_timeout(timeout):\n",
    "    @timeout_decor(timeout)\n",
    "    def get_data():\n",
    "        time.sleep(2)\n",
    "        return psutil.cpu_percent()        \n",
    "    \n",
    "    value=get_data()\n",
    "    if value is not None:\n",
    "        rc=1 # ok\n",
    "    else: \n",
    "        rc=0 # timeout\n",
    "    return (rc,value)    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    timeout=3.0                   \n",
    "    rc,value=get_data_with_timeout(timeout)\n",
    "    print(rc,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ./code/concurrency/demo_nonblocking_io_cpu.py\n",
    "import sys  \n",
    "sys.path.append('./code/concurrency/')  \n",
    "\n",
    "from nonblocking_io_cpu import get_data_with_timeout\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    timeout=3.0                   \n",
    "    rc,value=get_data_with_timeout(timeout)\n",
    "    print(rc,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Demo NonBlocking IO using Matplotlib.Plot\n",
    "\n",
    "\n",
    "Set `interval=1000`\n",
    "```python\n",
    "ani = FuncAnimation(fig, update,init_func=init, blit=True,interval=1000)\n",
    "```\n",
    "**Set IO time.sleep > interval=1000**\n",
    "\n",
    "```python\n",
    "time.sleep(2)\n",
    "```\n",
    "Test\n",
    "\n",
    "1. The IO is timeout `\n",
    "\n",
    "```python\n",
    " rc,value = get_data_with_timeout(1)\n",
    "```\n",
    "\n",
    "2. The IO is fast`\n",
    "\n",
    "```python\n",
    "time.sleep(0.1)\n",
    "```\n",
    "\n",
    "**Set IO time.sleep < interval=1000**\n",
    "\n",
    "```python\n",
    "time.sleep(0.5)\n",
    "```\n",
    "Test\n",
    "\n",
    "1. The IO is timeout `\n",
    "\n",
    "```python\n",
    " rc,value = get_data_with_timeout(1)\n",
    "```\n",
    "\n",
    "2. The IO is fast`\n",
    "\n",
    "```python\n",
    "time.sleep(0.1)\n",
    "```    \n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/concurrency/demo_nonblocking_io_cpu_matplotlib.py\n"
     ]
    }
   ],
   "source": [
    "%%file ./code/concurrency/demo_nonblocking_io_cpu_matplotlib.py\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import psutil\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import sys  \n",
    "sys.path.append('./code/concurrency/')  \n",
    "from nonblocking_io_cpu import get_data_with_timeout\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ln, = plt.plot([], [], 'b-o')\n",
    "str_cursecond=str(time.localtime(time.time()).tm_sec)   \n",
    "time_text = ax.text(0.5, 80, \"\")\n",
    "\n",
    "y = deque()\n",
    "\n",
    "def init():\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(1, 100)\n",
    "    return ln,\n",
    "\n",
    "def update(frames):\n",
    "    rc,value = get_data_with_timeout(3)\n",
    "    if len(y) < 10:\n",
    "        y.append(value)\n",
    "    else:\n",
    "        y.popleft()\n",
    "        y.append(value)\n",
    "    str_curtime=time.strftime(\"%F %H:%M:%S\", time.localtime(time.time()))  \n",
    "    if value is None:\n",
    "        str_cursecond=str_cursecond+\" (Timeout)\"\n",
    "    time_text.set_text(\"Time:\"+str_curtime)\n",
    "\n",
    "    ln.set_xdata(np.arange(len(y)))\n",
    "    ln.set_ydata(np.array(y))\n",
    "    return ln,time_text\n",
    "\n",
    "ani = FuncAnimation(fig, update,init_func=init, blit=True,interval=1000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data I/O Methods\n",
    "\n",
    "Now that we’ve seen what blocking and nonblocking functions entail, let’s look at how these concepts are involved with various operational modes of interface I/O. We’ll start with the simplest form, **on-demand I/O**（请求式I/O）, then proceed to **polled I/O**(轮询I/O）, and finally take a quick a look at **multithreaded I/O.**（多线程I/O）\n",
    "\n",
    "### 2.1 On-demand data I/O \n",
    "\n",
    "As I stated earlier, the two most obvious ways to move data into or out of your application are just a matter of reading from or writing to a port or device. \n",
    "\n",
    "When sending (writing) data using a serial (RS-232 or RS-485) or GPIB-type interface, there usually is `no need to worry about the use of a blocking call`. In the case of an RS-232 interface that does not use hardware handshaking, the data is sent out through the hardware port `immediately`. \n",
    "\n",
    "An RS-485 interface with `a single master and multiple listeners` should never block on a write by the master device, but the listeners may be unresponsive for a period of time. GPIB can also get into a situation where there are no listeners responding to the sender, but most GPIB interface APIs and the associated hardware can detect this and return an error code. \n",
    "\n",
    "Writing to a hardware interface API for a device such as a PCI interface card is usually not a problem in terms of blocking, but the call might still return an error code if something is amiss.\n",
    "\n",
    "If your software uses `on-demand calls` to read data, they should be `blocking calls`, and your software should always check the return codes. If `timeout parameters` are available for a blocking function call they should definitely be used, but not every API provides blocking calls with timeouts (perhaps it was assumed that a timeout couldn’t possibly happen). \n",
    "\n",
    "For those situations you’ll need to use a **nonblocking** version of the API function and employ a different approach to **implement a `timeout` in your own software**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.append('./code/concurrency/')  \n",
    "\n",
    "from nonblocking_io_cpu import get_data_with_timeout\n",
    "\n",
    "rc,value=get_data_with_timeout(4)\n",
    "print(rc,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Polled data I/O \n",
    "\n",
    "**A `nonblocking` call will return `immediately`**, and its return code or return value will (hopefully) let the caller know whether or not it succeeded. A nonblocking call can be used to `avoid an I/O hang`, but it requires more code to support it. \n",
    "\n",
    "For example, let’s assume that the API we’re using has both blocking and nonblocking versions of I/O functions to read data from a device, or perhaps that the I/O functions have a parameter that can be set to control blocking. You can then put a nonblocking call into a loop that also checks for a timeout, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from nonblocking_io_cpu import get_data_with_timeout\n",
    "\n",
    "def GetData(tmax=3):\n",
    "    checking = True\n",
    "    tstart = time.time()\n",
    "    while checking:\n",
    "        rc,value = get_data_with_timeout(tmax)\n",
    "        if rc == 1:\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(0.05) # wait 50 ms between checks\n",
    "    return rc, value\n",
    "\n",
    "rc,value=GetData(tmax=3)\n",
    "print(rc,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of **polling**: this function will attempt to get data from a specific data acquisition device by continually polling the port (using the **`get_data_with_limit()`** function call) until valid data appears. \n",
    "\n",
    "In between each read attempt it will `sleep` for 50 milliseconds. The delay is mainly for the benefit of the device being read, as many devices can’t tolerate being `hammered continuously for data`. \n",
    "\n",
    "In order to actually have a polling function that doesn’t cause the rest of an application to **suspend** while it’s active, you need to use **a thread**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Acquiring data using a thread with Callbacks\n",
    "\n",
    "So far we’ve looked at `on-demand` and `polled` data I/O. Now let’s take a quick look at how we might check for incoming data `without bogging down the entire system` in a continuous polling loop. \n",
    "\n",
    "**Callbacks**\n",
    "\n",
    "One of the simplest ways to accomplish this behavior is through **callbacks**. The strategy is quite similar to what we do when we request a cab.\n",
    "\n",
    "Imagine that you are at a restaurant and you've had a few drinks. It's raining outside, and you'd rather not take the bus; therefore, you request a taxi and ask them to `call when they're outside` so that you can come out, and you don't have to wait in the rain.\n",
    "\n",
    "What you did in this case is request a taxi (that is, the slow resource) but `instead of waiting outside until the taxi arrives`, you provide your number and instructions (**callback**) so that you can come outside `when they're ready` and go home.\n",
    "\n",
    "This technique of **`registering` callbacks for execution in response to certain events** is commonly called the ***Hollywood principle(好莱坞原则)**. This is because, after an audition for a role at Hollywood, you may be told  <b style=\"color:blue\">\"Don't call us, we'll call you\"</b>, meaning that they won't tell you if they chose you for the role immediately, but `they'll call you in case they do`(以通知替代轮询).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one API function `GetData()`. It is assumed that these exist as part of the API for the data acquisition hardware, and they do what their names imply. Also, the type of data being acquired isn’t specified, primarily because it doesn’t really matter for this example. It could be anything, just so long as the specified number of samples are acquired and no errors occur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "class AcqData:\n",
    "    \n",
    "    def __init__(self, timeout):\n",
    "        self.timeout = timeout\n",
    "        self.dvals = [] # list for acquired data values\n",
    "        self.dsamps = 0 # number of values actually read\n",
    "        self.get_rc = 0 # 0 is OK, negative value is an error\n",
    "        self.get_done = False # True if thread is finished\n",
    "   \n",
    "    def _get_data(self, numsamples):\n",
    "        cnt = 0\n",
    "        acqfail = False\n",
    "        \n",
    "        while not acqfail:\n",
    "            self.get_rc, dataval = GetData(self.timeout)\n",
    "            if self.get_rc == 1:\n",
    "                self.dsamps = cnt + 1\n",
    "                self.dvals.append(dataval)\n",
    "                cnt += 1\n",
    "                if cnt >= numsamples:\n",
    "                    break\n",
    "            else:\n",
    "                acqfail = True\n",
    "        \n",
    "        self.get_done = True\n",
    "\n",
    "    def StartDataSamples(self, samplecnt):\n",
    "        try:\n",
    "            acq_thread = threading.Thread(target=self._get_data,args=(samplecnt,))\n",
    "            acq_thread.start()\n",
    "            #acq_thread.join()\n",
    "        except Exception as e:\n",
    "            print(\"Acquire fault: {}\".format(str(e)))\n",
    "\n",
    "    def GetDataSamples(self):\n",
    "        if self.get_done == True:\n",
    "            return (self.get_rc, self.dsamps, self.dvals)\n",
    "        else:\n",
    "            return (None, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bit of code uses `a thread`, in the form of the function `_get_data()`, to continuously read the external device to obtain some number of data samples. Notice that `the hypothetical API function GetData()` supports the use of a `timeout` parameter, and we can assume that it will return an error code if a timeout does occur.\n",
    "\n",
    "The key things in this simple example are \n",
    "\n",
    "* **how the thread is created**, and \n",
    "\n",
    "* **how we can check to see if the data acquisition is complete**. \n",
    "\n",
    "Python’s threading library includes a thread object method called **join()**, which accepts an optional timeout parameter and\n",
    "is typically used to block the execution of one thread while it is waiting for another to complete. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case **we won’t use `join()`**, so the thread is allowed to run on its own. \n",
    "\n",
    "The accessor function `GetDataSamples()` checks the variable `self.get_done` to determine if the thread has finished. If so, `GetDataSamples()` will return the data collected.If the thread is still running, it will return a 3-tuple with the first item set to `None`.It is up to the caller to determine if the sample count returned matches the sample count requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AcqDataClient= AcqData(3)\n",
    "samplecnt=3\n",
    "AcqDataClient.StartDataSamples(samplecnt)\n",
    "while True:\n",
    "    get_rc,dsmaps,dvals=AcqDataClient.GetDataSamples()\n",
    "    print(\"AcqData ON -- \")\n",
    "    time.sleep(1)\n",
    "    if get_rc is not None:\n",
    "        print(get_rc,dsmaps,dvals)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is just one way to do this, but it illustrates a fundamental issue that is often encountered when working with threads; namely, \n",
    "\n",
    "* **at what point does the program come to a halt and wait for something else to finish what it’s doing?**\n",
    "\n",
    "In a program that is designed to run continuously, this can be dealt with by placing the call to `GetDataSamples()` in a single main loop in the application. This allows it to be checked each time through the loop if data is expected, with the results read back if they are available. Otherwise, the program could just continue to use the last known results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Communicating Between Threads\n",
    "\n",
    "**Problem**\n",
    "\n",
    "You have multiple threads in your program and you want to safely **communicate or exchange data** between them.\n",
    "\n",
    "One such interaction is the **producer/consumer** relationship. \n",
    "\n",
    "**Solution**\n",
    "\n",
    "Perhaps the safest way to send data from one thread to another is to use a **Queue** from the **queue** library. To do this, you create a Queue instance that is shared by the threads.\n",
    "\n",
    "Threads then use `put()` or `get(`) operations to add or remove items from the `queue`. \n",
    "\n",
    ">The principal challenge of multi-threaded applications is coordinating threads that share data or other resources. To that end, the threading module provides a number of synchronization primitives including locks, events, condition variables, and semaphores.\n",
    "While those tools are powerful, minor design errors can result in problems that are difficult to reproduce.\n",
    ">\n",
    ">So, the preferred approach to task coordination is to concentrate all access to a resource in a single thread\n",
    "and then use the queue module to feed that thread with requests from other threads. Applications using\n",
    "Queue objects for inter-thread communication and coordination are easier to design, more readable, and\n",
    "more reliable.\n",
    "\n",
    "#### 2.4.1 Queue\n",
    "**Queue** instances already have all of the required `locking`, so they can be safely shared by as many threads as you wish.\n",
    "\n",
    ">[queue — A synchronized queue class](https://docs.python.org/3/library/queue.html)\n",
    ">The queue module implements multi-producer, multi-consumer queues. It is especially useful in threaded programming when information must be exchanged safely between multiple threads\n",
    "\n",
    "When using `queues`, it can be somewhat tricky to coordinate the shutdown of the producer and consumer. A common solution to this problem is to rely on a special sentinel value, which when placed in the queue, causes consumers to terminate.\n",
    "\n",
    "If a thread needs to know **immediately** when a consumer thread has processed a particular item of data, you should pair the sent data with an **Event** object that allows the producer to monitor its progress. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread, Event\n",
    "import time\n",
    "import sys  \n",
    "sys.path.append('./code/')  \n",
    "\n",
    "from nonblocking_io_cpu import get_data_with_timeout\n",
    "\n",
    "def DataProducer(out_q):\n",
    "    tmax=3\n",
    "    checking = True\n",
    "    tstart = time.time()\n",
    "    while checking:\n",
    "        (rc,value) = get_data_with_timeout(tmax)\n",
    "        if rc == 1:\n",
    "            # Make an (data, event) pair and hand it to the consumer\n",
    "            evt = Event()\n",
    "            out_q.put(((rc,value), evt))\n",
    "            # Wait for the consumer to process the item\n",
    "            evt.wait()\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(0.05) # wait 50 ms between checks\n",
    "\n",
    "# A thread that consumes data\n",
    "def DataConsumer(in_q):\n",
    "    while True:\n",
    "        # Get some data\n",
    "        rcvalue, evt = in_q.get()\n",
    "        print(rcvalue[0],rcvalue[1])\n",
    "        # Indicate completion\n",
    "        evt.set()\n",
    "\n",
    "# Create the shared queue and launch both threads\n",
    "q = Queue()\n",
    "t1 = Thread(target=DataConsumer, args=(q,))\n",
    "t2 = Thread(target=DataProducer, args=(q,))\n",
    "t1.start()\n",
    "t2.start()\n",
    "# Wait for all produced items to be consumed\n",
    "q.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Timer\n",
    "\n",
    "**Timer Objects**\n",
    "\n",
    "This class represents an action that should be run only after a certain amount of time has passed — a timer. `Timer` is a subclass of `Thread` and as such also functions as an example of creating custom threads.\n",
    "\n",
    "Timers are started, as with threads, by calling their `start(`) method. The timer can be stopped (before its action has begun) by calling the `cancel()` method. The interval the timer will wait before executing its action may not be exactly the same as the interval specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread,Timer\n",
    "import time\n",
    "\n",
    "import sys  \n",
    "sys.path.append('./code/concurrency/') \n",
    "\n",
    "from nonblocking_io_cpu import get_data_with_timeout\n",
    "\n",
    "def PeriodDataProducer(delay,out_q):\n",
    "    tmax=3\n",
    "    rc,value= get_data_with_timeout(tmax)\n",
    "    if rc == 1:\n",
    "        out_q.put((rc,value))\n",
    "    else:\n",
    "        pass\n",
    "       \n",
    "    t=Timer(delay, PeriodDataProducer,(delay,out_q))\n",
    "    t.start()\n",
    "\n",
    "def DataConsumer(in_q):\n",
    "    while True:\n",
    "        rcvalue = in_q.get()\n",
    "        print(rcvalue[0],rcvalue[1])\n",
    "        \n",
    "q = Queue()\n",
    "p=PeriodDataProducer(2,q)\n",
    "c= Thread(target= DataConsumer, args=(q,)) \n",
    "c.start()\n",
    "q.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5  Using  Future and  Pebble \n",
    "\n",
    "We will program **nonblocking** IO interface function using **Future** and **Pebble** package\n",
    "\n",
    "Pebble provides a neat API to manage threads and processes within an application.\n",
    "```\n",
    ">python -m pip install Pebble\n",
    "```\n",
    "https://github.com/noxdafox/pebble\n",
    "\n",
    "#### 2.5.1 Non-blocking  IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/concurrency/nonblocking_io_cpu_pepple.py\n"
     ]
    }
   ],
   "source": [
    "%%file ./code/concurrency/nonblocking_io_cpu_pepple.py\n",
    "import time\n",
    "import psutil\n",
    "import pebble \n",
    "from concurrent.futures import TimeoutError\n",
    "\n",
    "def get_data():\n",
    "    time.sleep(0.5)\n",
    "    return psutil.cpu_percent()\n",
    "\n",
    "def get_data_with_timeout(timeout=1):\n",
    "    pool = pebble.ProcessPool(max_workers=1)\n",
    "    future = pool.schedule(get_data, args=(), timeout=timeout)\n",
    "    try:\n",
    "        result = future.result()\n",
    "        rc = 1\n",
    "        value = result\n",
    "    except TimeoutError:\n",
    "        rc = 0\n",
    "        value = None\n",
    "    except Exception as error:\n",
    "        rc = 0\n",
    "        value = None\n",
    "        print(error)\n",
    "    return (rc, value)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    rc,value = get_data_with_timeout(1)\n",
    "    print(rc,value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/concurrency/demo_nonblocking_io_cpu_pepple.py\n"
     ]
    }
   ],
   "source": [
    "%%file ./code/concurrency/demo_nonblocking_io_cpu_pepple.py\n",
    "import sys  \n",
    "sys.path.append('./code/')  \n",
    "\n",
    "from nonblocking_io_cpu_pepple import get_data_with_timeout\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    timeout=3\n",
    "    rc,value=get_data_with_timeout(timeout)\n",
    "    print(rc,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 Demo Non-blocking IO with Matplotlib.plot\n",
    "\n",
    "Set `Delay=1`\n",
    "````python\n",
    " rc, value = get_data_with_timeout(delay)\n",
    "```\n",
    "Test\n",
    "\n",
    "1. time.sleep < timeout\n",
    "\n",
    "```python\n",
    "def get_data():\n",
    "    time.sleep(0.5)\n",
    "    return psutil.cpu_percent()\n",
    "```\n",
    "2. time.sleep > timeout\n",
    "\n",
    "```python\n",
    "def get_data():\n",
    "    time.sleep(2)\n",
    "    return psutil.cpu_percent()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/concurrency/demo_nonblocking_io_cpu_pepple_loops_matplotlib.py\n"
     ]
    }
   ],
   "source": [
    "%%file ./code/concurrency/demo_nonblocking_io_cpu_pepple_loops_matplotlib.py\n",
    "from queue import Queue\n",
    "from threading import Thread, Timer\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('./code/concurrency/')\n",
    "\n",
    "from nonblocking_io_cpu_pepple import get_data_with_timeout\n",
    "\n",
    "\n",
    "def PeriodDataProducer(delay,out_q):\n",
    "    rc, value = get_data_with_timeout(delay)\n",
    "    if rc == 1:\n",
    "        out_q.put((rc, value))\n",
    "    else:\n",
    "        out_q.put((rc, value))\n",
    "\n",
    "    t = Timer(delay, PeriodDataProducer, (delay, out_q))\n",
    "    t.start()\n",
    "\n",
    "\n",
    "def DataConsumerPlot(in_q,npoints):\n",
    "    y = deque()\n",
    "    plt.figure()\n",
    "    plt.title(\"The Simplest CPU Percent Monitor\")\n",
    "    lines, = plt.plot([], [], \"b-o\")\n",
    "    time_text = plt.text(0.5, 80, \"\")\n",
    "    plt.xlim(0, npoints-1)\n",
    "    plt.ylim(0, 100)\n",
    "\n",
    "    def DataConsumer(in_q):\n",
    "        while True:\n",
    "            rcvalue = in_q.get()\n",
    "            if len(y) < 10:\n",
    "                y.append(rcvalue[1])\n",
    "            else:\n",
    "                y.popleft()\n",
    "                y.append(rcvalue[1])\n",
    "\n",
    "            lines.set_xdata(np.arange(len(y)))\n",
    "            lines.set_ydata(np.array(y))\n",
    "            str_curtime=time.strftime(\"%F %H:%M:%S\", time.localtime(time.time()))   \n",
    "            if rcvalue[1] is None:\n",
    "                str_cursecond=str_cursecond+\" (Timeout)\"\n",
    "            time_text.set_text(\"Time:\"+str_curtime)\n",
    "            plt.draw()\n",
    "\n",
    "    c = Thread(target=DataConsumer, args=(in_q,))\n",
    "    c.start()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    delay = 1\n",
    "    p = PeriodDataProducer(delay, q)\n",
    "    npoints = 10\n",
    "    DataConsumerPlot(q,npoints)\n",
    "    q.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Reactive programming\n",
    "\n",
    "**Reactive programming(响应式编程)** is a paradigm that aims at building better concurrent systems. Reactive applications are designed to comply with the requirements exemplified by the reactive manifesto:\n",
    "\n",
    "* **Responsive**: The system responds **immediately** to the user.\n",
    "\n",
    "* **Elastic**: The system is capable of handling different levels of load and is able to adapt to accommodate increasing demands.\n",
    "\n",
    "* **Resilient**: The system deals with failure gracefully. This is achieved by modularity and avoiding having a single point of failure.\n",
    "\n",
    "* **Message driven**: The system should not block and take advantage of `events` and `messages`. A message-driven application helps achieve all the previous requirements.\n",
    "\n",
    "As you can see, the intent of reactive systems is quite noble, but how exactly does reactiveprogramming work? In this section, we will learn about the principles of reactive programming using the **RxPy** library.\n",
    "\n",
    "```\n",
    "python -m pip install rx\n",
    "```\n",
    "\n",
    ">The RxPy library is part of [ReactiveX](http://reactivex.io), which is a project that implements reactive programming tools for a large variety of languages.\n",
    "\n",
    "```python\n",
    "#from nonblocking_io_cpu import get_data_with_timeout\n",
    "from nonblocking_io_cpu_pepple import get_data_with_timeout\n",
    "```\n",
    "\n",
    "Set `Delay=1`\n",
    "````python\n",
    " rc, value = get_data_with_timeout(delay)\n",
    "```\n",
    "Test\n",
    "\n",
    "1. time.sleep < timeout\n",
    "\n",
    "```python\n",
    "def get_data():\n",
    "    time.sleep(0.5)\n",
    "    return psutil.cpu_percent()\n",
    "```\n",
    "2. time.sleep > timeout\n",
    "\n",
    "```python\n",
    "def get_data():\n",
    "    time.sleep(2)\n",
    "    return psutil.cpu_percent()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/concurrency/demo_nonblcoking_io_cpu_reactive_matplotlib.py\n"
     ]
    }
   ],
   "source": [
    "%%file  ./code/concurrency/demo_nonblcoking_io_cpu_reactive_matplotlib.py\n",
    "from rx import Observable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import sys  \n",
    "sys.path.append('./code/concurrency/')\n",
    "\n",
    "#from nonblocking_io_cpu import get_data_with_timeout\n",
    "from nonblocking_io_cpu_pepple import get_data_with_timeout\n",
    "\n",
    "intervalTime=100\n",
    "delay=1\n",
    "cpu_data = (Observable\n",
    "            .interval(intervalTime) \n",
    "            .map(lambda rc,value: get_data_with_timeout(delay))\n",
    "            .publish())\n",
    "\n",
    "cpu_data.connect()\n",
    "\n",
    "def monitor_cpu(npoints):\n",
    "    plt.figure()\n",
    "    plt.title(\"The Simplest CPU Percent Monitor\")\n",
    "    lines, = plt.plot([], [],\"b-o\")\n",
    "    time_text = plt.text(0.5, 80, \"\")\n",
    "    plt.xlim(0, npoints-1)\n",
    "    plt.ylim(0, 100)\n",
    "    cpu_data_window = cpu_data.buffer_with_count(npoints, 1)\n",
    "    \n",
    "    def update_plot(cpu_readings):\n",
    "        lines.set_xdata(np.arange(len(cpu_readings)))\n",
    "        lines.set_ydata(np.array(cpu_readings)[:,1])\n",
    "        str_curtime=time.strftime(\"%F %H:%M:%S\", time.localtime(time.time()))  \n",
    "        \n",
    "        if np.array(cpu_readings)[-1,1] is None: \n",
    "            str_cursecond=str_cursecond+\" (Timeout)\"\n",
    "        \n",
    "        time_text.set_text(\"Time:\"+str_curtime)\n",
    "        plt.draw()\n",
    "    \n",
    "    cpu_data_window.subscribe(update_plot)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    monitor_cpu(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Handling Data I/O Errors\n",
    "\n",
    "No matter how unlikely it may seem, errors can still happen, especially when dealing with interfaces to the real world. They might be the result of spurious noise on a serial interface, an out-of-range voltage level on an analog input, or a fault in an external instrument. How the software detects and handles errors is directly related to its robustness. Another way to put it would be to say that robust software tends to exhibit a high degree of fault tolerance.\n",
    "\n",
    "For a system (be it software, hardware, or a combination of the two) to be called **faulttolerant** implies that it has the ability to detect a fault condition, take action to correct or bypass the fault, and continue to function (perhaps at a reduced level of functionality)\n",
    "instead of just crashing or abruptly halting. The ability to `continue to function at reduced levels of capability` in the presence of an increasing level of errors is called **graceful degradation**(优雅降级). Of course, if the errors continue to mount, at some point the system will eventually come to a halt, but the idea is that it will do so after giving ample notice and it will `not do it in a catastrophic fashion`.\n",
    "\n",
    "The reality is that there are almost always faults, and most things will eventually break\n",
    "or wear out. How much planning you should do for the mostly likely faults and the\n",
    "resulting errors is largely down to how much of a problem a failure will create. It might\n",
    "be insignificant (just ignore it and move on), or it could be a really big deal (something\n",
    "might explode, catch fire, or otherwise fail to stop an impending disaster). If you’ve\n",
    "done your up-front planning, as discussed in Chapter 8, you should be able to identify\n",
    "the nastiest scenarios and give some thought to how your system might deal with them\n",
    "should they arise.\n",
    "\n",
    "### 3.1 Classes of errors\n",
    "\n",
    "Errors can be grouped into two broad categories: **nonfatal** and **fatal**. A nonfatal error might be something like an intermittent communications channel, perhaps due to noise or other perturbations in the medium, or someone’s foot occasionally kicking a connector\n",
    "under a desk. Depending on the speed of the system and the duration of the failure, it may be possible to continue operation without adverse effects until communications can be reestablished. Another example might be an instrument that occasionally does not respond in a timely fashion, for whatever reason. If the command or query can be retried successfully with no ill effect, the error could be considered nonfatal.\n",
    "(Note that nonfatal does not mean nonannoying!)。\n",
    "\n",
    "A **fatal** error is one that requires significant intervention if the system is to continue functioning. Lacking that, it will need to perform a complete shutdown. An example of a fatal error would be the loss of control for the primary DC power supply used in an experiment. Unless there is a backup supply available that can automatically take over, the system will need to shut down until the problem can be resolved. Another example might be the failure of the control system for the liquid nitrogen supply used for the sorption pumps on a vacuum chamber, perhaps due to a failure in the control interface electronics, or a failure in the command communications channel. In either\n",
    "case, the system will begin to lose vacuum and potentially damage things like ion gauges or sputter emitters. At the very least, the current activity should be stopped until the problem is resolved.\n",
    "\n",
    "### 3.2 Error retry and system termination\n",
    "\n",
    "Sometimes it may make sense to retry an operation if an error is detected, perhaps after altering a parameter to compensate for the error. While this might sound clever (and it can be), it’s not something that should be done without some serious consideration of the context, cause, and consequences of the error. Blithely attempting to retry a failed operation can sometimes cause serious damage.\n",
    "\n",
    "The` more error-detection and self-recovery capabilities` one attempts to build into a system, the `more complicated` the system becomes. This is fairly obvious, to be sure, but what isn’t obvious is how that complexity will manifest, and the subsequent implications it might have, not only for a particular subsystem, but for the system as a whole. As complexity increases, so too does the chance of new defects being introduced. Increased complexity can also increase the number of possible execution paths in the software, some of which may be unintended.\n",
    "\n",
    "**Figure 11-11** shows a scheme for handling a data I/O error in a **fault-tolerant** fashion. While this approach may not be suitable for every application, it does show why robust or fault-tolerant software tends to be **an order of magnitude (or more) `more expensive`  to implement than something that just does the I/O operation and returns either `pass` or `fail`**. This is particularly true when performing testing to verify the fault-tolerant behavior. In **Figure 11-11**, there are `three possible paths` that can be taken should an\n",
    "error occur. In addition to the I/O operation itself, each of these paths must be tested by simulating the I/O and the error context. This rigorous testing involves a lot of work,but if you need that level of robustness there really is no other way to achieve it.\n",
    "\n",
    "![fault-tolerant fashion](./img/data-io-fault-resistant.jpg)\n",
    "\n",
    "An interesting point to note about `Figure 11-11` is the amount of code it implies. The data I/O operation and its return code (pass or fail, perhaps) are simple and straightforward, and might take no more than a line or two of code to implement. With the error handling included in the design, the code for performing a data I/O operation will grow by anywhere from 10 to 100 times in size. `This is typical of fault-tolerant software`.A large portion of it is concerned with error detection and handling, and only a fraction actually deals directly with the I/O. Also note that the last decision block, **“Backup active?,”** means that if the backup is already in use (i.e., the test is True), there are no more options left except to fail.\n",
    "\n",
    "When detecting and attempting to deal with an error, the system has to make a decision as to whether to attempt to recover from the error (and what recovery strategy to use)or just try to shut down gracefully. The logic making that decision must have inputs in the form of data describing the context in which the error occurred and the current state of the system, and there may also be a need to define excluded operations that should not be used.\n",
    "\n",
    "For example, it may not be a good idea for a system controlling a pressure vessel to just\n",
    "relinquish control of the system without first performing some kind of check to determine\n",
    "if the pressure needs to be released. If the pressure continues to build even after\n",
    "the pumps and heaters are disabled (this can happen), there is a risk that the vessel may\n",
    "explode, especially if the error involved an over-pressure-related situation to start with.\n",
    "A graceful shutdown could possibly involve some type of venting action before control\n",
    "is completely terminated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if an error occurs in a system that is moving a mass of some type, does it make sense for the system to just stop? If the action of lifting or moving the mass entails control of power to a motor or servo, it might not be a good idea to just kill the power \n",
    "\n",
    "The system may need to engage some type of braking or locking mechanism, or it might make sense for the mass to be lowered to a safe position prior to shutdown (if possible).\n",
    "\n",
    "These considerations also come into play when attempting to retry a failed operation.Retries may not be appropriate after some types of failures, such as the loss of direct positional feedback, or the failure of a temperature sensor. Other failures may be known to be transient, and the operations can be retried some number of times before the situation is declared hopeless.\n",
    "\n",
    "Consider the situation where the position of a secondary mechanism is dependent on the position of a primary mechanism, both of which are moving at a slow and relatively continuous rate for extended periods of time. The link between the two is a communications channel that is known to occasionally drop out due to system load or other factors. In a situation like this, the secondary mechanism that is following the primary one might be able to predict where it should be over short periods of time. This allows it to continue to function without an update from the primary mechanism. If after some period of time the communications with the primary mechanism cannot be reestablished,the secondary mechanism will enter an error condition. If it does reestablish the communications channel with the primary mechanism before the timeout period, it can update its position, if necessary, and reset the timeout\n",
    "\n",
    "\n",
    "Failure analysis, which we discussed briefly in the section **“Handling Errors and Faults” on page 272 in Chapter 8**, comes into play when making decisions like these.If done correctly, it can provide the guidance needed to make the decision to terminate abruptly, terminate gracefully, or attempt to recover. Lacking a failure analysis, the best choice is often to just terminate gracefully, and provide sufficient information (typically in a crash log or something similar) to allow someone to go back and ascertain the cause of the problem later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Allen B. Downey. [Think OS:A Brief Introduction to Operating Systems](http://greenteapress.com/wp/think-os/)\n",
    "\n",
    "\n",
    "[The Python Standard Library:Concurrent Execution](https://docs.python.org/3/library/concurrency.html)\n",
    "\n",
    "* [threading — Thread-based parallelism](https://docs.python.org/3/library/threading.html)\n",
    "\n",
    "* [queue — A synchronized queue class](https://docs.python.org/3/library/queue.html)\n",
    "\n",
    "\n",
    "[Networking and Interprocess Communication](https://docs.python.org/3/library/ipc.html)\n",
    "\n",
    "  * asyncio — Asynchronous I/O https://docs.python.org/3/library/asyncio.html  \n",
    "\n",
    "Pebble： https://github.com/noxdafox/pebble\n",
    "\n",
    "\n",
    "J. M. Hughes. Real World Instrumentation with Python, O'Reilly Media, December 2010\n",
    "\n",
    "\n",
    "Doug Hellmann. The Python3 Standard Library by Example,Pearson Education, Inc. 2017\n",
    "\n",
    "* http://doughellmann.com/blog/the-python-3-standard-library-by-example\n",
    "\n",
    "* Python 3 Module of the Week https://pymotw.com/3/\n",
    "   \n",
    "\n",
    "Gabriele Lanaro. Python High Performance,Second Edition, Packt Publishing,2017\n",
    "\n",
    "\n",
    "David Beazley, Brian K. Jone. Python Cookbook, Third Edition. O’Reilly Media,2013\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295.38px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
